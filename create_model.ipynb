{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_model",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beryl2208/Keras-TensorFlow/blob/master/create_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Yu2aigd6dfpF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2msmjgYvSOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bb18d98b-4cd7-4653-bc55-6a47c33a9b37"
      },
      "cell_type": "code",
      "source": [
        "#PREPROCESS DATA\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load training data set from CSV file\n",
        "training_data_df = pd.read_csv(\"sales_data_training.csv\")\n",
        "\n",
        "# Load testing data set from CSV file\n",
        "test_data_df = pd.read_csv(\"sales_data_test.csv\")\n",
        "\n",
        "# Data needs to be scaled to a small range like 0 to 1 for the neural\n",
        "# network to work well.\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Scale both the training inputs and outputs\n",
        "scaled_training = scaler.fit_transform(training_data_df)\n",
        "scaled_testing = scaler.transform(test_data_df)\n",
        "\n",
        "# Print out the adjustment that the scaler applied to the total_earnings column of data\n",
        "print(\"Note: total_earnings values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[8], scaler.min_[8]))\n",
        "\n",
        "# Create new pandas DataFrame objects from the scaled data\n",
        "scaled_training_df = pd.DataFrame(scaled_training, columns=training_data_df.columns.values)\n",
        "scaled_testing_df = pd.DataFrame(scaled_testing, columns=test_data_df.columns.values)\n",
        "\n",
        "# Save scaled data dataframes to new CSV files\n",
        "scaled_training_df.to_csv(\"sales_data_training_scaled.csv\", index=False)\n",
        "scaled_testing_df.to_csv(\"sales_data_testing_scaled.csv\", index=False)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: total_earnings values were scaled by multiplying by 0.0000036968 and adding -0.115913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "c4MO4gWuexf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "\n",
        "training_data_df = pd.read_csv(\"sales_data_training_scaled.csv\")\n",
        "\n",
        "X = training_data_df.drop('total_earnings', axis=1).values\n",
        "Y = training_data_df[['total_earnings']].values\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=9, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YHzC5kGdhkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}